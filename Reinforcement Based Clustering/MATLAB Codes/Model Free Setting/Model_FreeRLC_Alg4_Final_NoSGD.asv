%% Algorithm 4: Deep Clustering Algorithm (large N/ continuous X) - No SGD
tic;clear all; clc; rng(1);
MaxInnerTheta = 200;                % policy update loop max iterations
MaxInnerY = 200;                    % max iterations in Y update loop
MaxInner = [500, 250];
NN_update = 50;
v = VideoWriter('CheckingMiniBatchSGDPerformanceRun2.mp4', 'Motion JPEG 2000');  % or 'Motion JPEG AVI'
v.FrameRate = 1;  % frames per second
open(v);
% ------------------ initialization ------------------- 
for inner = 1 : size(MaxInner,1)
    
    close all; clc; 
    idx = 4; [X,K,T_P,M,N] = data_RLClustering_ModelFree(idx);
    [X,mu1,sig] = zscore(X);
    col = zeros(K,3);
    for k = 1 : K
        col(k,:) = rand(1,3);
    end
    
    T = 0.5; Tmin = 0.001; tau1 = 0.9;    % annealing parameters
    eps = 1;                          % for epsilon greedy policy 
    Sz_miniBatch = 256;                 % size of the minibatch for both nets and Y
    buf_cap = 1000;                   % memory or replay capacity
    
    
    H_target = MaxInnerTheta/10;        % steps between target net updates
    mu = 0.9;
    gamma = 0.001;                      % learning rate for policy SGD update
    tau = 1;
    
    Px = (1/M)*ones(M,1);               % weight for each user data point
    [idx_clust, Y] = kmeans(X,K);        % Starting with Y
    
    P = 1/K*ones(M,K);                  % Policy 
    
    idx_input = randi([1 length(X)],[Sz_miniBatch,1]);
    init_trainInput = zeros(Sz_miniBatch,N+K+K*N);
    init_trainOutput = zeros(Sz_miniBatch,1);
    for i = 1 : Sz_miniBatch   
        temp = zeros(K,1); temp(idx_clust(idx_input(i)),1) = 1;
        Y_S = Y + 0.5*randn(K,N);
        init_trainInput(i,:) = [X(idx_input(i),:) temp' Y_S(:)'];
        init_trainOutput(i) = norm(X(idx_input(i),:)-Y(idx_clust(idx_input(i)),:))^2;
    end
    init_trainInput = init_trainInput';
    init_trainOutput = init_trainOutput';
    Y = repmat(Px'*X, [K,1]) + 0.001*randn(K,N);
    
    net = fitnet([15 10], 'trainlm');
    net.performParam.regularization = 0.15;
    net.performParam.normalization = 'standard';
    %net = feedforwardnet([10 10], 'trainlm');
    net.trainParam.epochs = 250; 
    net.trainParam.showWindow = false;
    net = train(net, init_trainInput, init_trainOutput);
    
    net_target = net;
    
    memory.i = zeros(buf_cap,1); memory.j = zeros(buf_cap,1);
    memory.k = zeros(buf_cap,1); memory.d = zeros(buf_cap,1);
    memory.Yloc = zeros(buf_cap,8);
    buf_n = 0;                          % current size of the memory
    circ_ptr = 1;                       % circular pointer
    thetaPrev = getwb(net);
    K_consec = 20;
    epsTheta = 1e-06;
    epsY = 1e-04;

    MaxInnerTheta = MaxInner(inner,1);
    MaxInnerY = MaxInner(inner,2);
    count = 1;
    while T >= Tmin
        
        % ===== "policy" loop: update P given current Y =====
        eps = 0.99;
        smallCnt = 0;
        Yold = Y;
        for t = 1 : MaxInnerTheta * 2
            i = randi(M); % sampling a user data point
            d_bar = zeros(K,1);
            for j = 1 : K
                %d_bar(j) = nn_forward(theta_target, X(i,:), Y(j,:));
                temp = zeros(K,1); temp(j) = 1;
                d_bar(j) = net_target([X(i,:), temp', Y(:)']');
            end
            d_bar2 = d_bar - min(d_bar,[],2);
            num = exp(-(1/T)*d_bar2);
            den = sum(num);
            P(i,:) = num/den;
    
            % epsilon-greedy method for action selection
            if rand < eps
                j = randi(K);
            else
                %[~,j] = max(P(i,:));
                j = randsample(1:K, 1, true, P(i,:));
            end
            
            k = randsample(1:K, 1, true, T_P(:,j,i));   % sample the cluster k using T_P
            dist = norm(X(i,:) - Y(k,:))^2;            
            if buf_n < buf_cap
                loc = circ_ptr; buf_n = buf_n + 1;
            else
                loc = circ_ptr;
            end
            circ_ptr = circ_ptr + 1; 
            if circ_ptr > buf_cap
                circ_ptr = 1;
            end
    
            memory.i(loc) = i; memory.j(loc) = j; 
            memory.k(loc) = k; memory.d(loc) = dist;
            memory.Yloc(loc,:) = Y(:)';
    
            % train theta when enough data is available
            if buf_n >= Sz_miniBatch && mod(t,25) == 0
                miniBatch = randi(buf_n, Sz_miniBatch, 1);   % uniformly sample
                miniBatchDataX = zeros(Sz_miniBatch,N+K+K*N);
                miniBatchDataY = zeros(Sz_miniBatch,1);
                for b = 1 : Sz_miniBatch
                    ii = memory.i(miniBatch(b));
                    jj = memory.j(miniBatch(b));
                    d_t = memory.d(miniBatch(b));
                    Y_S = memory.Yloc(miniBatch(b),:);
                    temp = zeros(K,1); temp(jj) = 1;
                    miniBatchDataX(b,:) = [X(ii,:), temp', Y_S(:)'];
                    miniBatchDataY(b) = d_t;
                end
                net.trainParam.epochs = 100; net.divideFcn = 'dividetrain';
                [net,tr] = train(net, miniBatchDataX', miniBatchDataY');
            end
            thetaNow  = getwb(net);
            dthetaRel = norm(thetaNow - thetaPrev) / (norm(thetaPrev) + 1e-12);
            if dthetaRel < epsTheta
                smallCnt = smallCnt + 1;
            else
                smallCnt = 0;
            end
            thetaPrev = thetaNow;
    
            % target network sunc
            tau2 = 0.01;
            
            for ii = 1: numel(net.IW)
                net_target.IW{ii} = tau2*net.IW{ii} + (1-tau2)*net_target.IW{ii};
            end

            for ii = 1 : numel(net.LW)
                net_target.LW{ii} = tau2*net.LW{ii} + (1-tau2)*net_target.LW{ii};
            end

            for ii = 1 : numel(net.b)
                net_target.b{ii} = tau2*net.b{ii} + (1-tau2)*net_target.b{ii};
            end
            % if mod(t, 100) == 0
            %     net_target = net;
            % end
            % %disp(t);
            eps = eps*0.999;
            a = -0.1; b = 0.1;
            Y = Yold + (a+(b-a)*rand(K,2)); % Okay practically as long as T_P doesn't depend on Y
            %disp(Y);
        end
        Y = Yold;
        %Y = Y + 0.1*randn(K,N);
        for t = 1 : MaxInnerY

          lb2 = Y - [0.05,0.05]; ub2 = Y + [0.05,0.05];
            
            idx = randperm(buf_n,100);
            [Y,Fval,C] = minimize_F_NoSGD(net,X(idx,:),Y,lb2,ub2,T);
        end


        d_hat = zeros(M,K);
        for j1 = 1 : K
            temp = zeros(K,1); temp(j1) = 1;
            d_hat(:,j1) = net_target([X, repmat(temp',[M,1]) repmat(Y(:)',[M,1])]')';
        end
        d_hat = d_hat - min(d_hat,[],2);
        num = exp(-(1/T)*d_hat); den = sum(num,2);
        Pij = num./repmat(den,[1 size(num,2)]);
        disp(Y);
        disp(Fval);
        disp(T);
        T = tau1*T;
        
        %[~, ~] = min(C,[],2);
        %d_hat = C;
        %d_hat = d_hat - min(d_hat,[],2);
        %num = exp(-(1/T)*d_hat); den = sum(num,2);
        %Pij = num./repmat(den,[1 size(num,2)]);
        %idx = cell(K,1);
        col_all = Pij(:,1:K) * col(1:K,:);

        % Plot all points at once
        scatter(X(:,1), X(:,2), 90, col_all, 'filled', ...
            'MarkerEdgeColor','k', 'LineWidth', 0.15); hold on;
        for k = 1 : K
            scatter(Y(k,1),Y(k,2),500,'p','MarkerEdgeColor', 'k', 'MarkerFaceColor', col(k,:), 'LineWidth',2);
        end
        xlim([-2 2]); ylim([-2 2]); axis square; box on;
        set(gca, 'FontSize', 25); set(gca, 'LineWidth', 1.0);
        xticks([-2 0 2]); yticks([-2 0 2]); hold off;
        frame = getframe(gcf);       % gcf = current figure
        writeVideo(v, frame);

        count = count + 1;
        %Y = Y + 0.05*randn(K,N);
        %a = -0.025; b = 0.025;
        %Y = Y + (a+(b-a)*rand(K,2));
        net = init(net);
    end
    

    P_idx = zeros(M,1);
    for i = 1 : M
        d_bar = zeros(K,1);
        for j = 1 : K
            temp = zeros(K,1); temp(j) = 1;
            d_bar(j) = net_target([X(i,:), temp', Y(:)']');
        end
        d_bar = d_bar-min(d_bar);
        num = exp(-(1/T)*d_bar);
        den = sum(num);
        P(i,:) = num/den;
        [~,P_idx(i)] = min(d_bar);
    end
    
    idx = cell(K,1);
    for k = 1 : K
        idx{k} = find(P_idx==k);
        col = rand(1,3);
        scatter(X(idx{k},1),X(idx{k},2),90,'filled','MarkerEdgeColor','k',...
            'MarkerFaceColor',col,'LineWidth',0.25); hold on;
        scatter(Y(k,1),Y(k,2),500,'p','MarkerEdgeColor', 'k', 'MarkerFaceColor', col, 'LineWidth',2);
    end
    xlim([-2 2]); ylim([-2 2]); axis square; box on;
    set(gca, 'FontSize', 25); set(gca, 'LineWidth', 1.0);
    xticks([-2 0 2]); yticks([-2 0 2]); hold off;
    title("MaxInnerTheta = " + MaxInnerTheta + " MaxInnerY = " + MaxInnerY);
    name = ['SGD_Mod_Run_' num2str(MaxInnerTheta) '_' num2str(MaxInnerY) '.png'];
    print(gcf, name, '-dpng', '-r600');
    name = ['SGD_Mod_Run_Results_' num2str(MaxInnerTheta) '_' num2str(MaxInnerY) '.mat'];
    save(name)
end
toc;